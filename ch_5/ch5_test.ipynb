{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:06.675396Z",
     "start_time": "2025-04-08T12:13:36.442964800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n",
      "torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n",
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([3.9108e-05, 5.6776e-05, 4.7559e-06])\n",
      "tensor([ -9.5042, -10.3796, -11.3677, -10.1492,  -9.7764, -12.2561])\n",
      "tensor(-10.5722)\n",
      "tensor(10.5722)\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "tensor(10.5722)\n",
      "Characters: 20479\n",
      "Tokens: 5145\n",
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.981106758117676\n",
      "------ Ep 1 (Step 000000): Train loss 9.830, Val loss 9.927\n",
      "------ Ep 1 (Step 000005): Train loss 8.133, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "------ Ep 2 (Step 000010): Train loss 6.770, Val loss 7.048\n",
      "------ Ep 2 (Step 000015): Train loss 6.497, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "------ Ep 3 (Step 000020): Train loss 5.579, Val loss 6.490\n",
      "------ Ep 3 (Step 000025): Train loss 4.732, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "------ Ep 4 (Step 000030): Train loss 5.284, Val loss 6.360\n",
      "------ Ep 4 (Step 000035): Train loss 3.855, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "------ Ep 5 (Step 000040): Train loss 3.667, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "------ Ep 6 (Step 000045): Train loss 3.600, Val loss 6.139\n",
      "------ Ep 6 (Step 000050): Train loss 2.383, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "------ Ep 7 (Step 000055): Train loss 2.336, Val loss 6.138\n",
      "------ Ep 7 (Step 000060): Train loss 2.696, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "------ Ep 8 (Step 000065): Train loss 1.596, Val loss 6.176\n",
      "------ Ep 8 (Step 000070): Train loss 1.346, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "------ Ep 9 (Step 000075): Train loss 1.100, Val loss 6.277\n",
      "------ Ep 9 (Step 000080): Train loss 0.672, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "------ Ep 10 (Step 000085): Train loss 0.531, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from ch_4.build_gpt import GPTModel, generate_text_simple\n",
    "from ch_2.dataloader import create_dataloader_v1\n",
    "\n",
    "'''\n",
    "1.1：使用 GPT 生成文本\n",
    "'''\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,  # 我们将上下文长度从1024个token缩短到256个token\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,  # 将 dropout 设置为 0 是一种常见的做法\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Utility functions for text to token ID conversion\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "'''\n",
    "1.2：计算文本生成损失\n",
    "'''\n",
    "inputs = torch.tensor([[16833, 3626, 6100],  # [\"every effort moves\",\n",
    "                       [40, 1107, 588]])  # \"I really like\"]\n",
    "# Matching these inputs, the `targets` contain the token IDs we aim for the model to produce:\n",
    "targets = torch.tensor([[3626, 6100, 345],  # [\" effort moves you\",\n",
    "                        [107, 588, 11311]])  # \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度跟踪，因为我们尚未进行训练\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)  # Probability of each token in vocabulary\n",
    "print(probas.shape)\n",
    "\n",
    "# 通过对概率得分应用 argmax 函数，可以得到对应的 token ID\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "\n",
    "# 将token ID 转换回文本\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "# When we decode these tokens, we find that these output tokens are quite different from the target tokens we want the model to generate:\n",
    "# Targets batch 1: effort moves you\n",
    "# Outputs batch 1: Armed heNetflix\n",
    "\n",
    "# 对于这两个输入文本，我们可以通过以下代码打印与目标 token 对应的初始 softmax 概率得分\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)\n",
    "\n",
    "'''\n",
    "如何最大化目标 token 的 softmax 概率值？整体思路是通过更新模型权重，使模型在生成目标 token 时输出更高的概率值。\n",
    "通过反向传播：需要一个损失函数，该函数用于计算模型预测输出与实际目标输出之间的差异（此处指与目标 token ID 对应的概率）。这个损失函数用于衡量模型预测与目标值的偏差程度\n",
    "\n",
    "在机器学习，特别是 PyTorch 等框架中，cross_entropy 函数用于计算离散输出的损失，与模型生成的 token 概率下的目标 token 的负平均对数概率类似\n",
    "'''\n",
    "# 对这些目标token的概率得分取对数\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "\n",
    "# 接下来，通过计算平均值将这些对数概率合并为一个评分\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "\n",
    "# 在深度学习中，常见做法并不是直接将平均对数概率推向 0，而是通过将负平均对数概率降低至 0 来实现\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)\n",
    "\n",
    "# 在 PyTorch 中，cross_entropy 函数能够自动完成所有上面的步骤计算损失值\n",
    "# 在 PyTorch 中使用交叉熵损失函数时，我们需要将这些张量展平，以便在批量维度上进行合并\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)\n",
    "\n",
    "'''\n",
    "1.3：计算训练集和验证集的损失\n",
    "'''\n",
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)\n",
    "\n",
    "# 首先定义一个 train_ratio，用于将 90% 的数据用于训练，剩余 10% 用于在训练期间进行模型评估\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "# 复用第 2 章中的 create_dataloader_v1 代码来创建相应的数据加载器（训练数据集和测试数据集）\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "\n",
    "# 输入数据（x）和目标数据（y）的形状相同（即批次大小 × 每批的 token 数量），因为目标数据是将输入数据整体向后偏移一个位置得到的\n",
    "# print(\"Train loader:\")\n",
    "# for x, y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#\n",
    "# print(\"\\nValidation loader:\")\n",
    "# for x, y in val_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "\n",
    "\n",
    "# 实现一个工具函数calc_loss_batch，用于计算由训练和验证加载器返回的批量数据的交叉熵损失\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)  # 将数据传输到指定设备（如 GPU），使数据能够在 GPU 上处理。\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "# calc_loss_loader 将用于计算指定数据加载器中的指定数据批次的损失\n",
    "# Function to compute the training and validation loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)  # A\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))  # B\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()  # C\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches  # D\n",
    "\n",
    "\n",
    "# A 如果没有指定批次数，将自动遍历所有批次\n",
    "# B 若批次数超过数据加载器的总批次数，则减少批次数使其与数据加载器的批次数相匹配\n",
    "# C 每个批次的损失求和\n",
    "# D 对所有批次的损失取平均值\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # A\n",
    "model.to(device)\n",
    "with torch.no_grad():  # B\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)  # C\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "# A 如果你的设备配备了支持 CUDA 的 GPU，LLM 将自动在 GPU 上进行训练，无需更改代码\n",
    "# B 因为当前不在训练，为提高效率，关闭梯度跟踪\n",
    "# C 通过 device 设置确保数据与 LLM 模型加载到同一设备上\n",
    "\n",
    "'''\n",
    "2：预训练LLM\n",
    "'''\n",
    "# the main function for pretraining LLMs\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []  # A\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):  # B\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # C\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # D\n",
    "            optimizer.step()  # E\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:  # F\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"------ Ep {epoch + 1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(  # G\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "# A 初始化用于记录损失和已处理 token 数量的列表\n",
    "# B 开始主训练循环\n",
    "# C 重置上一批次的损失梯度\n",
    "# D 计算损失梯度\n",
    "# E 使用损失梯度更新模型权重\n",
    "# F 可选的评估步骤\n",
    "# G 每个 epoch 结束后打印示例文本\n",
    "\n",
    "# evaluate_model 函数会在训练集和验证集上计算损失，同时确保模型处于评估模式，并在计算损失时禁用梯度跟踪和 dropout\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # A\n",
    "    with torch.no_grad():  # B\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "# A 评估阶段禁用 dropout，以确保结果稳定、可复现\n",
    "# B 禁用梯度跟踪，减少计算开销\n",
    "\n",
    "# generate_and_print_sample text函数则通过生成的实际文本示例，帮助我们在训练过程中判断模型的能力\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "\n",
    "'''\n",
    "实例化一个GPT model，开始训练\n",
    "'''\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)  # A\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x300 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 先创建一个简单的图表，将训练集和验证集损失并排展示\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()  # A\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # B\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "# A 创建与 y 轴共用的第二个 x 轴\n",
    "# B 用于对齐刻度的隐藏图形"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:36.309441100Z",
     "start_time": "2025-04-08T12:18:35.998393800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "在一个较小的数据集上进行多轮训练，容易产生过拟合的现象的原因：\n",
    "1. 模型容量与数据集大小的匹配问题\n",
    "2. 多轮训练导致对数据集细节的过度学习\n",
    "3. 数据集的多样性不足\n",
    "4. 过拟合与模型泛化能力的矛盾\n",
    "'''\n",
    "\n",
    "'''\n",
    "3: 通过解码策略控制生成结果的随机性\n",
    "'''\n",
    "# LLM 的文本生成策略，以减少训练数据的记忆倾向，提升 LLM 生成文本的原创性\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "'''\n",
    "3.1：Temperature scaling（一种在生成下一个词时加入概率选择的技术）\n",
    "\n",
    "为了实现概率采样过程，现在可以用 PyTorch 中的 multinomial 函数代替 argmax\n",
    "'''\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:41.065754700Z",
     "start_time": "2025-04-08T12:18:39.456582200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 假设给 LLM 一个初始上下文‘every effort moves you’，并生成下一个 token 的 logits 分数\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:44.618005300Z",
     "start_time": "2025-04-08T12:18:44.612681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n",
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "# 为了实现概率采样过程，现在可以用 PyTorch 中的 multinomial 函数代替 argmax\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])\n",
    "\n",
    "# “forward” 依然是最有可能的 token，因此大多数情况下会被 multinomial 选中，但并不是每次都选中\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:46.748464200Z",
     "start_time": "2025-04-08T12:18:46.695704900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x300 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNiElEQVR4nO3dd1gUV/s38O9Sl0UBka7UYAFBpSSKRsESiLHEmJ/ErgiWmICIFY2KBUuiiF2s2GLUaEj04VExiYqxREEskaAICFEIARVQAsjuef/gZR7XZXGpM+D9ua694p49M/td3HgzM2fOETHGGAghhBAiSGp8ByCEEEKIclSoCSGEEAGjQk0IIYQIGBVqQgghRMCoUBNCCCECRoWaEEIIETAq1IQQQoiAUaEmhBBCBEyD7wCNTSaT4fHjx2jZsiVEIhHfcQghhLyFGGMoKiqChYUF1NSqP2Z+6wr148ePYWlpyXcMQgghBFlZWWjbtm21fd66Qt2yZUsAFT8cPT09ntMQQgh5GxUWFsLS0pKrSdV56wp15eluPT09KtSEEEJ4pcolWBpMRgghhAgYr4X6woULGDx4MCwsLCASiRATE/PGbc6fPw83NzeIxWLY2dlh27ZtDR+UEEII4QmvhfrFixfo0qULNm3apFL/9PR0fPTRR+jVqxdu3LiB+fPnIygoCMeOHWvgpIQQQgg/eL1GPWDAAAwYMEDl/tu2bYOVlRUiIyMBAA4ODrh+/TrWrFmDTz/9tIFSEkIam1QqxcuXL/mOQUitaWpqQl1dvV721aQGk12+fBne3t5ybT4+Pti1axdevnwJTU1NhW1KS0tRWlrKPS8sLGzwnISQ2mGMIScnB8+ePeM7CiF1ZmBgADMzszrP2dGkCnVOTg5MTU3l2kxNTVFeXo68vDyYm5srbLNy5UosWbKksSISQuqgskibmJhAIpHQpESkSWKMobi4GLm5uQBQZW2qiSZVqAHFoeyMsSrbK4WGhiIkJIR7XnnvGiFEWKRSKVekW7duzXccQupER0cHAJCbmwsTE5M6nQZvUoXazMwMOTk5cm25ubnQ0NBQ+j+2trY2tLW1GyMeIaoL06/mtYLGyyEgldekJRIJz0kIqR+V3+WXL1/WqVA3qfuoPTw8EBcXJ9d25swZuLu7V3l9mhDS9NDpbtJc1Nd3mddC/fz5cyQlJSEpKQlAxe1XSUlJyMzMBFBx2nrcuHFc/6lTp+Lhw4cICQlBcnIydu/ejV27dmHWrFl8xCeEEEIaHK+nvq9fv44+ffpwzyuvJY8fPx7R0dHIzs7mijYA2NraIjY2FjNmzMDmzZthYWGBDRs20K1ZhBBCmi1eC7WXlxc3GKwq0dHRCm2enp5ITExswFSEEKGxmfefRn2/jFUDVe77ptOblQcezYmXlxe6du3KzWnRFG3fvh3ffvstEhMTUVRUhKdPn8LAwIDvWFVqUoPJCCFEaLKzs7k/Hz58GIsWLUJKSgrXVjn6tylQNh9Fc3m/VxUXF+PDDz/Ehx9+iNDQUF4yqKpJDSYjhBChMTMz4x76+voQiURybRcuXJBbn2DJkiUoLy/ntheJRIiKisKgQYMgkUjg4OCAy5cvIzU1FV5eXtDV1YWHhwcePHjAbRMWFoauXbsiKioKlpaWkEgkGD58uMJEMXv27IGDgwPEYjE6duyILVu2cK9lZGRAJBLhyJEj8PLyglgsxoEDB5Cfn4+RI0eibdu2kEgkcHZ2xqFDh7jtJkyYgPPnz2P9+vUQiUQQiUTIyMhAdHS0whFpTEyM3BmHyty7d++GnZ0dtLW1wRhDQUEBJk+eDBMTE+jp6aFv3764efNmPf0NVS04OBjz5s1D9+7dG/R96gMVakIIaSCnT5/GmDFjEBQUhLt37yIqKgrR0dEIDw+X67ds2TKMGzcOSUlJ6NixI0aNGoUpU6YgNDQU169fBwB8+eWXctukpqbiyJEjOHHiBE6dOoWkpCR88cUX3Os7duzAggULEB4ejuTkZKxYsQILFy7E3r175fYzd+5cBAUFITk5GT4+PigpKYGbmxtOnjyJO3fuYPLkyRg7diyuXr0KAFi/fj08PDwwadIkZGdnIzs7u0ZzU1TmPnbsGDeQeODAgcjJyUFsbCwSEhLg6uqKfv364cmTJ0r306lTJ7Ro0ULpo1OnTipnEjo69U0IIQ0kPDwc8+bNw/jx4wEAdnZ2WLZsGebMmYPFixdz/fz8/ODr6wugonB6eHhg4cKF8PHxAQBMnz4dfn5+cvsuKSnB3r170bZtWwDAxo0bMXDgQKxduxZmZmZYtmwZ1q5di2HDhgGoGIxb+ctCZR6g4siysk+lV++kCQwMxKlTp3D06FF069YN+vr60NLSgkQigZmZWY1/JmVlZdi/fz+MjY0BAL/88gtu376N3Nxcbs6LNWvWICYmBt9//z0mT55c5X5iY2OrnQ++Od2yS4WaEEIaSEJCAq5duyZ3BC2VSlFSUoLi4mJuQozOnTtzr1dOk+zs7CzXVlJSgsLCQujp6QEArKysuCINVMwzIZPJkJKSAnV1dWRlZcHf3x+TJk3i+pSXl0NfX36yHXd3d7nnUqkUq1atwuHDh/Ho0SNuvQRdXd26/jgAANbW1lyRBip+Rs+fP1eYtOrff/+VO91f1X7eFlSoCSGkgchkMixZskThiBUAxGIx9+dXj/4qr+lW1SaTyZS+V2UfkUjE9duxYwe6desm1+/1GbJeL8Br167FunXrEBkZCWdnZ+jq6iI4OBhlZWXKPygANTU1hbt4qjriff39ZDIZzM3Nce7cOYW+1Y3C7tSpEx4+fKj0dWtra/zxxx/VZm4qqFATQkgDcXV1RUpKCuzt7et935mZmXj8+DEsLCwAVKwuqKamhvbt28PU1BRt2rRBWloaRo8eXaP9xsfH4+OPP8aYMWMAVBTS+/fvw8HBgeujpaUFqVQqt52xsTGKiorw4sULrhhXXoOujqurK3JycqChoQEbGxuVc9Kpb0IIIXW2aNEiDBo0CJaWlhg+fDjU1NRw69Yt3L59G8uXL6/TvsViMcaPH481a9agsLAQQUFB8PX15a4bh4WFISgoCHp6ehgwYABKS0tx/fp1PH36VG6hotfZ29vj2LFjuHTpElq1aoWIiAjk5OTIFWobGxtcvXoVGRkZaNGiBQwNDdGtWzdIJBLMnz8fgYGB+P3331W6f7x///7w8PDA0KFDsXr1anTo0AGPHz9GbGwshg4dqnBqvlJdT33n5OQgJycHqampAIDbt2+jZcuWsLKygqGhYZ32Xd9o1DchhDQQHx8fnDx5EnFxcXj33XfRvXt3RERE1Mv1VXt7ewwbNgwfffQRvL294eTkJHf7VUBAAHbu3Ino6Gg4OzvD09MT0dHRsLW1rXa/CxcuhKurK3x8fODl5QUzMzMMHTpUrs+sWbOgrq4OR0dHGBsbIzMzE4aGhjhw4ABiY2O5W7rCwsLe+DlEIhFiY2PRu3dvTJw4Ee3bt8eIESOQkZGhsKxxfdq2bRtcXFy4a/i9e/eGi4sLfvrppwZ7z9oSseqmBmuGCgsLoa+vj4KCAm5QBiGNjlbPUlBSUoL09HTY2trKXb8lisLCwhATE6PSqWXCn+q+0zWpRXRETQghhAgYFWpCCCFEwKhQE0JIExMWFkanvd8iVKgJIYQQAaNCTQghhAgYFWpCCCFEwKhQE0IIIQJGhZoQQggRMCrUhBBCiIBRoSaEkDoQiUTVPiZMmMB3xHrn5eWF4OBgvmPUSWlpKQIDA2FkZARdXV0MGTIEf/31V7XbXLhwAYMHD4aFhQVEIhFiYmIaJSstykEIEb7qplxtkPdTfRrX7Oxs7s+HDx/GokWLkJKSwrXp6OjUa7SG9PLly0Zddaqx3+9VwcHBOHHiBL777ju0bt0aM2fOxKBBg5CQkKCwFGilFy9eoEuXLvDz88Onn37aaFnpiJoQQurAzMyMe+jr60MkEsm1XbhwAW5ubhCLxbCzs8OSJUtQXl7ObS8SiRAVFYVBgwZBIpHAwcEBly9fRmpqKry8vKCrqwsPDw88ePCA2yYsLAxdu3ZFVFQULC0tIZFIMHz4cDx79kwu2549e+Dg4ACxWIyOHTvKLdqRkZEBkUiEI0eOwMvLC2KxGAcOHEB+fj5GjhyJtm3bQiKRcAtsVJowYQLOnz+P9evXc2cNMjIyEB0drbB+dExMDLdO9qu5d+/eDTs7O2hra4MxhoKCAkyePBkmJibQ09ND3759cfPmzXr6G1JUUFCAXbt2Ye3atejfvz9cXFxw4MAB3L59G2fPnlW63YABA7B8+fIq1xdvSFSoCSGkgZw+fRpjxoxBUFAQ7t69i6ioKERHRyM8PFyu37JlyzBu3DgkJSWhY8eOGDVqFKZMmYLQ0FBcv34dAPDll1/KbZOamoojR47gxIkTOHXqFJKSkvDFF19wr+/YsQMLFixAeHg4kpOTsWLFCixcuBB79+6V28/cuXMRFBSE5ORk+Pj4oKSkBG5ubjh58iTu3LmDyZMnY+zYsbh69SoAYP369fDw8MCkSZOQnZ2N7OxsWFpaqvwzqcx97Ngxbna1gQMHIicnB7GxsUhISICrqyv69euHJ0+eKN1Pp06d0KJFC6WPTp06Kd02ISEBL1++hLe3N9dmYWEBJycnXLp0SeXP0ljo1DchhDSQ8PBwzJs3D+PHjwcA2NnZYdmyZZgzZw4WL17M9fPz84Ovry+AisLp4eGBhQsXwsfHBwAwffp0+Pn5ye27pKQEe/fuRdu2bQEAGzduxMCBA7F27VqYmZlh2bJlWLt2LXf0Z2try/2yUJkHqDgF/PoR4qxZs7g/BwYG4tSpUzh69Ci6desGfX19aGlpQSKRcGtf10RZWRn2798PY2NjAMAvv/yC27dvIzc3F9ra2gCANWvWICYmBt9//z0mT55c5X5iY2Px8uVLpe9T3Sn1nJwcaGlpoVWrVnLtpqamyMnJqelHanBUqAkhpIEkJCTg2rVrckfQUqkUJSUlKC4uhkQiAQB07tyZe71yDWZnZ2e5tpKSEhQWFnJLIlpZWXFFGgA8PDwgk8mQkpICdXV1ZGVlwd/fn1tvGQDKy8uhry9/vd/d3V3uuVQqxapVq3D48GE8evQIpaWlKC0tha6ubl1/HAAAa2trrkgDFT+j58+fo3Xr1nL9/v33X7nT/VXtp74xxuRO1QsFFWpCCGkgMpkMS5YsqfKa5qvrE7969FdZKKpqk8lkSt+rso9IJOL67dixA926dZPr9/pAqdcL8Nq1a7Fu3TpERkbC2dkZurq6CA4ORllZmfIPCkBNTQ2MMbm2qo54X38/mUwGc3NznDt3TqHv69e8X9WpUyc8fPhQ6evW1tb4448/qnzNzMwMZWVlePr0qdxRdW5uLnr06KF0n3yhQk0IIQ3E1dUVKSkpsLe3r/d9Z2Zm4vHjx7CwsAAAXL58GWpqamjfvj1MTU3Rpk0bpKWlYfTo0TXab3x8PD7++GOMGTMGQEUhvX//PhwcHLg+WlpakEqlctsZGxujqKgIL1684IqxKit8ubq6IicnBxoaGrCxsVE5Z11Ofbu5uUFTUxNxcXHcJYfs7GzcuXMHX3/9tcoZGgsVakIIaSCLFi3CoEGDYGlpieHDh0NNTQ23bt3C7du3sXz58jrtWywWY/z48VizZg0KCwsRFBQEX19f7rpxWFgYgoKCoKenhwEDBqC0tBTXr1/H06dPERISonS/9vb2OHbsGC5duoRWrVohIiICOTk5coXaxsYGV69eRUZGBlq0aAFDQ0N069YNEokE8+fPR2BgIH7//XdER0e/8XP0798fHh4eGDp0KFavXo0OHTrg8ePHiI2NxdChQxVOzVeqy6lvfX19+Pv7Y+bMmWjdujUMDQ0xa9YsODs7o3///ly/fv364ZNPPuEG8j1//hypqanc6+np6UhKSoKhoSGsrKxqnedNeB/1vWXLFtja2kIsFsPNzQ3x8fHV9j948CC6dOkCiUQCc3Nz+Pn5IT8/v5HSEkKI6nx8fHDy5EnExcXh3XffRffu3REREVEv11ft7e0xbNgwfPTRR/D29oaTk5Pc7VcBAQHYuXMnoqOj4ezsDE9PT0RHR8PW1rba/S5cuBCurq7w8fGBl5cXzMzMMHToULk+s2bNgrq6OhwdHWFsbIzMzEwYGhriwIEDiI2N5W7pCgsLe+PnEIlEiI2NRe/evTFx4kS0b98eI0aMQEZGBne9viGsW7cOQ4cOha+vL3r27AmJRIITJ07IXRp48OAB8vLyuOfXr1+Hi4sLXFxcAAAhISFwcXHBokWLGiwnAIjY6xcVGtHhw4cxduxYbNmyBT179kRUVBR27tyJu3fvVvnbycWLF+Hp6Yl169Zh8ODBePToEaZOnYp27drhhx9+UOk9CwsLoa+vj4KCAm5QBiGNrroJPGow2UZzUlJSgvT0dO4Xd6JcWFgYYmJiVDq1TPhT3Xe6JrWI1yPqiIgI+Pv7IyAgAA4ODoiMjISlpSW2bt1aZf8rV67AxsYGQUFBsLW1xfvvv48pU6Zw9xkSQgghzQ1vhbqsrAwJCQlyN5wDgLe3t9Ibznv06IG//voLsbGxYIzh77//xvfff4+BAwc2RmRCCCGk0fFWqPPy8iCVShWuQVR3w3mPHj1w8OBBfPbZZ9DS0oKZmRkMDAywceNGpe9TWlqKwsJCuQchhDRlYWFhdNr7LcL7YLLXby6v7obzu3fvIigoCIsWLUJCQgJOnTqF9PR0TJ06Ven+V65cCX19fe5Rk6nuCCGEEL7xVqiNjIygrq6ucPScm5urdKTfypUr0bNnT8yePRudO3eGj48PtmzZgt27d8utYPOq0NBQFBQUcI+srKx6/yyEEEJIQ+GtUGtpacHNzQ1xcXFy7XFxcUpnhikuLoaamnzkyqH0ygava2trQ09PT+5BCCGENBW8nvoOCQnBzp07sXv3biQnJ2PGjBnIzMzkTmWHhoZi3LhxXP/Bgwfj+PHj2Lp1K9LS0vDbb78hKCgI7733Hjc7DyGEENKc8Doz2WeffYb8/HwsXboU2dnZcHJyQmxsLDcZQHZ2NjIzM7n+EyZMQFFRETZt2oSZM2fCwMAAffv2xerVq/n6CIQQQkiD4nXCEz7QhCdEEGjCEwU04QlpbprFhCeEEEIIqR4VakIIqQORSFTtY8KECXxHrHdeXl4IDg7mO0adeHl5KfxdjRgxgu9YVaLVswghgue817lR3+/2+Nsq93311tDDhw9j0aJFSElJ4dp0dHTqNVtDevnyZbXLQzb193vdpEmTsHTpUu65UP+u6IiaEELqwMzMjHvo6+tDJBLJtV24cAFubm4Qi8Wws7PDkiVLUF5ezm0vEokQFRWFQYMGQSKRwMHBAZcvX0Zqaiq8vLygq6sLDw8PPHjwgNsmLCwMXbt2RVRUFCwtLSGRSDB8+HA8e/ZMLtuePXvg4OAAsViMjh07yq2ulZGRAZFIhCNHjsDLywtisRgHDhxAfn4+Ro4cibZt20IikXArYVWaMGECzp8/j/Xr13NHohkZGYiOjoaBgYHc+8fExMhNYFWZe/fu3bCzs4O2tjYYYygoKMDkyZNhYmICPT099O3bFzdv3qynvyHlJBKJwt+fEFGhJoSQBnL69GmMGTMGQUFBuHv3LqKiohAdHY3w8HC5fsuWLcO4ceOQlJSEjh07YtSoUZgyZQpCQ0O5RYcq10SulJqaiiNHjuDEiRM4deoUkpKS8MUXX3Cv79ixAwsWLEB4eDiSk5OxYsUKLFy4EHv37pXbz9y5cxEUFITk5GT4+PigpKQEbm5uOHnyJO7cuYPJkydj7NixuHr1KgBg/fr18PDwwKRJk5CdnY3s7OwazfhYmfvYsWPcNKgDBw5ETk4OYmNjkZCQAFdXV/Tr1w9PnjxRup9OnTqhRYsWSh+dOnV6Y5aDBw/CyMgInTp1wqxZs1BUVKTy52hMdOqbEEIaSHh4OObNm4fx48cDAOzs7LBs2TLMmTMHixcv5vr5+fnB19cXQEXh9PDwwMKFC+Hj4wMAmD59Ovz8/OT2XVJSgr1796Jt27YAgI0bN2LgwIFYu3YtzMzMsGzZMqxduxbDhg0DANja2nK/LFTmAYDg4GCuT6VZs2Zxfw4MDMSpU6dw9OhRdOvWDfr6+tDS0uKORmuqrKwM+/fvh7GxMQDgl19+we3bt5GbmwttbW0AwJo1axATE4Pvv/8ekydPrnI/sbGxePnypdL3edMp9dGjR8PW1hZmZma4c+cOQkNDcfPmTYVJuISACjUhhDSQhIQEXLt2Te4IWiqVoqSkBMXFxZBIJACAzp07c69XTqHs7Ows11ZSUoLCwkLuVh4rKyuuSAOAh4cHZDIZUlJSoK6ujqysLPj7+2PSpElcn/LycoXTu+7u7nLPpVIpVq1ahcOHD+PRo0coLS1FaWkpdHV16/rjAABYW1tzRRqo+Bk9f/4crVu3luv377//yp3ur2o/dfHqz8XJyQnt2rWDu7s7EhMT4erqWqd91zcq1IQQ0kBkMhmWLFmicMQKQO6+2leP/iqv6VbVJpPJlL5XZR+RSMT127FjB7p16ybXr3La5UqvF+C1a9di3bp1iIyMhLOzM3R1dREcHIyysjLlHxSAmpqawlTOVR3xvv5+MpkM5ubmOHfunELf1695v6pTp054+PCh0tetra3xxx9/VJv5Va6urtDU1MT9+/epUBNCyNvC1dUVKSkpsLe3r/d9Z2Zm4vHjx9z0yZcvX4aamhrat28PU1NTtGnTBmlpaRg9enSN9hsfH4+PP/4YY8aMAVBRSO/fvw8HBweuj5aWFqRSqdx2xsbGKCoqwosXL7hirMpSnK6ursjJyYGGhgZsbGxUzlnXU9+v++OPP/Dy5UuYm5vXaLvGQIWaEEIayKJFizBo0CBYWlpi+PDhUFNTw61bt3D79m0sX768TvsWi8UYP3481qxZg8LCQgQFBcHX15e7bhwWFoagoCDo6elhwIABKC0txfXr1/H06VOEhIQo3a+9vT2OHTuGS5cuoVWrVoiIiEBOTo5cobaxscHVq1eRkZGBFi1awNDQEN26dYNEIsH8+fMRGBiI33//HdHR0W/8HP3794eHhweGDh2K1atXo0OHDnj8+DFiY2MxdOhQhVPzlepy6vvBgwc4ePAgPvroIxgZGeHu3buYOXMmXFxc0LNnz1rvt6HQqG9CCGkgPj4+OHnyJOLi4vDuu++ie/fuiIiIqPP1VaCioA4bNgwfffQRvL294eTkJHf7VUBAAHbu3Ino6Gg4OzvD09MT0dHRsLW1rXa/CxcuhKurK3x8fODl5QUzMzMMHTpUrs+sWbOgrq4OR0dHGBsbIzMzE4aGhjhw4ABiY2O5W7rCwsLe+DlEIhFiY2PRu3dvTJw4Ee3bt8eIESOQkZGhdMnjutLS0sLPP/8MHx8fdOjQAUFBQfD29sbZs2cVLg0IAc31TQgfaK5vBTTXt+rCwsIQExOj0qllwh+a65sQQgh5C1ChJoQQQgSMCjUhhDQxYWFhdNr7LVKrQh0dHY3i4uL6zkIIIYSQ19SqUIeGhsLMzAz+/v64dOlSfWcihBBCyP9Xq0L9119/4cCBA3j69Cn69OmDjh07YvXq1cjJyanvfISQt8xbdiMKacbq67tcq0Ktrq6OIUOG4Pjx48jKysLkyZNx8OBBWFlZYciQIfjxxx+rneqOEEJeVzmTFF1WI81F5Xe5rmtu13lmMhMTE/Ts2RMpKSm4d+8ebt++jQkTJsDAwAB79uyBl5dXXd+CEPIWUFdXh4GBAXJzcwFUrBX86lrGhDQVjDEUFxcjNzcXBgYGdZ5EpdaF+u+//8b+/fuxZ88epKWlYejQoTh58iT69++Pf//9F1999RXGjx9f7aTphBDyqsrpLyuLNSFNmYGBQa2WAn1drWYmGzx4ME6fPo327dsjICAA48aNg6GhoVyfx48fo23btoI7BU4zkxFBoJnJqiWVSqtdcIEQodPU1Kz2SLomtahWR9QmJiY4f/48PDw8lPYxNzdHenp6bXZPCHnLqaurC3LOZUL4UKvBZJ6enlWu11lWVoZ9+/YBqJhovT4mnieEEELeZrUq1H5+figoUDw9V1RUBD8/vzqHIoQQQkiFWhVqxliVozH/+usv6OtXc+2NEEIIITVSo2vULi4uEIlEEIlE6NevHzQ0/re5VCpFeno6Pvzww3oPSQghhLytalSoKxcPT0pKgo+PD1q0aMG9pqWlBRsbG3z66af1GpAQQgh5m9WoUC9evBgAYGNjg88++4wWdyeEEEIaWK2uUY8fP77eivSWLVtga2sLsVgMNzc3xMfHV9u/tLQUCxYsgLW1NbS1tfHOO+9g9+7d9ZKFEEIIERqVj6gNDQ1x7949GBkZoVWrVtVO7ffkyROV9nn48GEEBwdjy5Yt6NmzJ6KiojBgwADcvXsXVlZWVW7j6+uLv//+G7t27YK9vT1yc3NRXl6u6scghBBCmhSVC/W6devQsmVL7s/1MQdvREQE/P39ERAQAACIjIzE6dOnsXXrVqxcuVKh/6lTp3D+/HmkpaVxM6HZ2NjUOQchhBAiVCoX6vHjx3N/njBhQp3fuKysDAkJCZg3b55cu7e3t9I1rn/66Se4u7vj66+/xv79+6Grq4shQ4Zg2bJl0NHRqXKb0tJSlJaWcs8LCwvrnJ0QQghpLCoX6poUOFXm0M7Ly4NUKoWpqalcu6mpqdJ1rdPS0nDx4kWIxWL88MMPyMvLw7Rp0/DkyROl16lXrlyJJUuWqJydEEIIERKVC7WBgcEbT3dXToQilUpVDvD6PpVNpgIAMpkMIpEIBw8e5CZWiYiIwP/93/9h8+bNVR5Vh4aGIiQkhHteWFgIS0tLlfMRQgghfFK5UP/666/1+sZGRkZQV1dXOHrOzc1VOMquZG5ujjZt2sjNfubg4ADGGP766y+0a9dOYRttbW1oa2vXa3ZCCCGksahcqD09Pev1jbW0tODm5oa4uDh88sknXHtcXBw+/vjjKrfp2bMnjh49iufPn3OTrdy7dw9qampo27ZtveYjhBBChEDlQn3r1i04OTlBTU0Nt27dqrZv586dVdpnSEgIxo4dC3d3d3h4eGD79u3IzMzE1KlTAVSctn706BG3IteoUaOwbNky+Pn5YcmSJcjLy8Ps2bMxceJEpYPJCCGEkKZM5ULdtWtX5OTkwMTEBF27doVIJAJjTKFfTa5Rf/bZZ8jPz8fSpUuRnZ0NJycnxMbGcstjZmdnIzMzk+vfokULxMXFITAwEO7u7mjdujV8fX2xfPlyVT8GIYQQ0qSIWFXVtgoPHz6ElZUVRCIRHj58WG1fIa9DXVhYCH19fRQUFKg0Op2QurCZ958q2zPEo5RvFKa4hCwhpHmpSS1S+Yj61eIr5EJMCCGENCc1WpTjVSkpKdi4cSOSk5MhEonQsWNHBAYGokOHDvWZjxBCCHmr1WpRju+//x5OTk5ISEhAly5d0LlzZyQmJsLJyQlHjx6t74yEEELIW6tWR9Rz5sxBaGgoli5dKte+ePFizJ07F8OHD6+XcIQQQsjbrlZH1Dk5ORg3bpxC+5gxY5RO/0kIIYSQmqtVofby8qpy3eiLFy+iV69edQ5FCCGEkAoqn/r+6aefuD8PGTIEc+fORUJCArp37w4AuHLlCo4ePUoLYBBCCCH1SOX7qNXUVDv4rumiHI2N7qMmjYnuoyaEVKVB7qOWyWR1DkYIIYSQmqnVNWpCCCGENI5aT3jy4sULnD9/HpmZmSgrK5N7LSgoqM7BCCGEEFLLQn3jxg189NFHKC4uxosXL2BoaIi8vDxIJBKYmJhQoSaEEELqSa1Ofc+YMQODBw/GkydPoKOjgytXruDhw4dwc3PDmjVr6jsjIYQQ8taqVaFOSkrCzJkzoa6uDnV1dZSWlsLS0hJff/015s+fX98ZCSGEkLdWrQq1pqYmRCIRAMDU1JRbM1pfX19u/WhCCCGE1E2trlG7uLjg+vXraN++Pfr06YNFixYhLy8P+/fvh7Ozc31nJIQQQt5atTqiXrFiBczNzQEAy5YtQ+vWrfH5558jNzcX27dvr9eAhBBCyNusVkfU7u7u3J+NjY0RGxtbb4EIIYQQ8j+1vo8aAHJzc5GSkgKRSIQOHTrA2Ni4vnIRQgghBLU89V1YWIixY8eiTZs28PT0RO/evWFhYYExY8agoIDmKSaEEELqS60KdUBAAK5evYqTJ0/i2bNnKCgowMmTJ3H9+nVMmjSpvjMSQgghb61anfr+z3/+g9OnT+P999/n2nx8fLBjxw58+OGH9RaOEEIIedvV6oi6devW0NfXV2jX19dHq1at6hyKEEIIIRVqVai/+uorhISEIDs7m2vLycnB7NmzsXDhwnoLRwghhLztVD717eLiws1GBgD379+HtbU1rKysAACZmZnQ1tbGP//8gylTptR/UkIIIeQtpHKhHjp0aAPGIIQQQkhVVC7UixcvbsgchBBCCKlCnSY8SUhIQHJyMkQiERwdHeHi4lJfuQghhBCCWhbq3NxcjBgxAufOnYOBgQEYYygoKECfPn3w3Xff0QxlhBBCSD2p1ajvwMBAFBYW4o8//sCTJ0/w9OlT3LlzB4WFhQgKCqrRvrZs2QJbW1uIxWK4ubkhPj5epe1+++03aGhooGvXrrX4BIQQQkjTUKtCferUKWzduhUODg5cm6OjIzZv3oz//ve/Ku/n8OHDCA4OxoIFC3Djxg306tULAwYMeOOa1gUFBRg3bhz69etXm/iEEEJIk1GrQi2TyaCpqanQrqmpCZlMpvJ+IiIi4O/vj4CAADg4OCAyMhKWlpbYunVrtdtNmTIFo0aNgoeHR42zE0IIIU1JrQp13759MX36dDx+/Jhre/ToEWbMmKHyUW5ZWRkSEhLg7e0t1+7t7Y1Lly4p3W7Pnj148OCByqPQS0tLUVhYKPcghBBCmopaFepNmzahqKgINjY2eOedd2Bvbw9bW1sUFRVh48aNKu0jLy8PUqkUpqamcu2mpqbIycmpcpv79+9j3rx5OHjwIDQ0VBsHt3LlSujr63MPS0tLlbYjhBBChKBWo74tLS2RmJiIuLg4/Pnnn2CMwdHREf3796/xvl6d7QwAGGMKbQAglUoxatQoLFmyBO3bt1d5/6GhoQgJCeGeFxYWUrEmhBDSZNS4UJeXl0MsFiMpKQkffPABPvjgg1q9sZGREdTV1RWOnnNzcxWOsgGgqKgI169fx40bN/Dll18CqLhWzhiDhoYGzpw5g759+ypsp62tDW1t7VplJIQQQvhW41PfGhoasLa2hlQqrdMba2lpwc3NDXFxcXLtcXFx6NGjh0J/PT093L59G0lJSdxj6tSp6NChA5KSktCtW7c65SGEEEKEqFanvr/66iuEhobiwIEDMDQ0rPWbh4SEYOzYsXB3d4eHhwe2b9+OzMxMTJ06FUDFaetHjx5h3759UFNTg5OTk9z2JiYmEIvFCu2EEEJIc1GrQr1hwwakpqbCwsIC1tbW0NXVlXs9MTFRpf189tlnyM/Px9KlS5GdnQ0nJyfExsbC2toaAJCdnf3Ge6oJIYSQ5kzEGGM13WjJkiUQiURQtqmQF/AoLCyEvr4+CgoKoKenx3cc0szZzPtPle0Z4lHKNworaKA0hBChqEktqtERdXFxMWbPno2YmBi8fPkS/fr1w8aNG2FkZFSnwIQQQgipWo0Gky1evBjR0dEYOHAgRo4cibNnz+Lzzz9vqGyEEELIW69GR9THjx/Hrl27MGLECADA6NGj0bNnT0ilUqirqzdIQEIIIcKg9FLOqoGNnOTtUqMj6qysLPTq1Yt7/t5770FDQ0NuKlFCCCGE1J8aFWqpVAotLS25Ng0NDZSXl9drKEIIIYRUqNGpb8YYJkyYIDfTV0lJCaZOnSp3i9bx48frLyEhhBDyFqtRoR4/frxC25gxY+otDCGEEELk1ahQ79mzp6FyEEIIIaQKtVrmkhBCCCGNgwo1IYQQImBUqAkhhBABo0JNCCGECBgVakIIIUTAqFATQgghAkaFmhBCCBEwKtSEEEKIgFGhJoQQQgSMCjUhhBAiYFSoCSGEEAGjQk0IIYQIGBVqQgghRMCoUBNCCCECRoWaEEIIETAq1IQQQoiAUaEmhBBCBEyD7wCEEHnOe52VvnZ7/O1GTEIIEQI6oiaEEEIEjAo1IYQQImC8F+otW7bA1tYWYrEYbm5uiI+PV9r3+PHj+OCDD2BsbAw9PT14eHjg9OnTjZiWEEIIaVy8XqM+fPgwgoODsWXLFvTs2RNRUVEYMGAA7t69CysrK4X+Fy5cwAcffIAVK1bAwMAAe/bsweDBg3H16lW4uLjw8AkIIYRUh8Zc1B2vR9QRERHw9/dHQEAAHBwcEBkZCUtLS2zdurXK/pGRkZgzZw7effddtGvXDitWrEC7du1w4sSJRk5OCCGENA7eCnVZWRkSEhLg7e0t1+7t7Y1Lly6ptA+ZTIaioiIYGho2RERCCCGEd7yd+s7Ly4NUKoWpqalcu6mpKXJyclTax9q1a/HixQv4+voq7VNaWorS0lLueWFhYe0CE0IIITzgfTCZSCSSe84YU2iryqFDhxAWFobDhw/DxMREab+VK1dCX1+fe1haWtY5MyGEENJYeCvURkZGUFdXVzh6zs3NVTjKft3hw4fh7++PI0eOoH///tX2DQ0NRUFBAffIysqqc3ZCCCGksfBWqLW0tODm5oa4uDi59ri4OPTo0UPpdocOHcKECRPw7bffYuDAgW98H21tbejp6ck9CCGEkKaC19uzQkJCMHbsWLi7u8PDwwPbt29HZmYmpk6dCqDiaPjRo0fYt28fgIoiPW7cOKxfvx7du3fnjsZ1dHSgr6/P2+cghBBCGgqvhfqzzz5Dfn4+li5diuzsbDg5OSE2NhbW1tYAgOzsbGRmZnL9o6KiUF5eji+++AJffPEF1z5+/HhER0c3dnxCCCGkwfG+KMe0adMwbdq0Kl97vfieO3eu4QMRQgghAsL7qG9CCCGEKEeFmhBCCBEwKtSEEEKIgPF+jfptRRPVE0IIUQUdURNCCCECRoWaEEIIETAq1IQQQoiAUaEmhBBCBIwKNSGEECJgVKgJIYQQAaNCTQghhAgYFWpCCCFEwKhQE0IIIQJGhZoQQggRMCrUhBBCiIBRoSaEEEIEjBblIITUGS0yQ5oToX2f6YiaEEIIETAq1IQQQoiA0alvojKhnQ4ihJC3AR1RE0IIIQJGhZoQQggRMDr1XUc28/6j9LWMVQMbMQkhhJDmiI6oCSGEEAGjQk0IIYQIGJ36Js0ajVQnyjTF70ZTzEzqjo6oCSGEEAGjQk0IIYQIGBVqQgghRMB4L9RbtmyBra0txGIx3NzcEB8fX23/8+fPw83NDWKxGHZ2dti2bVsjJSWEEEIaH6+F+vDhwwgODsaCBQtw48YN9OrVCwMGDEBmZmaV/dPT0/HRRx+hV69euHHjBubPn4+goCAcO3askZMTQgghjYPXQh0REQF/f38EBATAwcEBkZGRsLS0xNatW6vsv23bNlhZWSEyMhIODg4ICAjAxIkTsWbNmkZOTgghhDQO3m7PKisrQ0JCAubNmyfX7u3tjUuXLlW5zeXLl+Ht7S3X5uPjg127duHly5fQ1NRssLyEEEKUCNNX/pqtVePlaKZ4K9R5eXmQSqUwNTWVazc1NUVOTk6V2+Tk5FTZv7y8HHl5eTA3N1fYprS0FKWlpdzzgoICAEBhYWFdPwIAQFZarPS16t5D+q+0VtvVB6fFp5W+dmeJj9LX+MxcW3xnVvb9KBQxpdvwnVnZ94O+G/zjOzN9n+svc+V+GFP+s+Mwnjx69IgBYJcuXZJrX758OevQoUOV27Rr146tWLFCru3ixYsMAMvOzq5ym8WLFzMA9KAHPehBD3oI7pGVlfXGesnbEbWRkRHU1dUVjp5zc3MVjpormZmZVdlfQ0MDrVu3rnKb0NBQhISEcM9lMhmePHmC1q1bQyQS1fFTyCssLISlpSWysrKgp6dXr/tuKJS5cVDmxkGZGwdlrjvGGIqKimBhYfHGvrwVai0tLbi5uSEuLg6ffPIJ1x4XF4ePP/64ym08PDxw4sQJubYzZ87A3d1d6fVpbW1taGtry7UZGBjULfwb6OnpCeKLUBOUuXFQ5sZBmRsHZa4bfX19lfrxOuo7JCQEO3fuxO7du5GcnIwZM2YgMzMTU6dOBVBxNDxu3Diu/9SpU/Hw4UOEhIQgOTkZu3fvxq5duzBr1iy+PgIhhBDSoHhdlOOzzz5Dfn4+li5diuzsbDg5OSE2NhbW1tYAgOzsbLl7qm1tbREbG4sZM2Zg8+bNsLCwwIYNG/Dpp5/y9REIIYSQBsX76lnTpk3DtGnTqnwtOjpaoc3T0xOJiYkNnKp2tLW1sXjxYoVT7UJGmRsHZW4clLlxUObGJWJMlbHhhBBCCOED73N9E0IIIUQ5KtSEEEKIgFGhJoQQQgSMCjUhhBAiYFSo66C8vBx79+5VOjc5IYQQUlc06ruOJBIJkpOTuXu/m4IJEyZg4sSJ6N27N99RVGZnZ4dr164pTBX77NkzuLq6Ii0tjadk//PTTz+p3HfIkCENmOTtJpVKcfv2bVhbW6NVq1Z8x2myarL4hFBm+nrdhQsXqn29qfwbyPt91E1dt27dkJSU1KQKdVFREby9vWFpaQk/Pz+MHz8ebdq04TtWtTIyMiCVKq5oU1paikePHvGQSNHQoUPlnotEIrmVcV6dW76qzyIEe/fuhZGREQYOHAgAmDNnDrZv3w5HR0ccOnRIkN/z4OBgODs7w9/fH1KpFJ6enrh06RIkEglOnjwJLy8vviM2SQYGBiqvhyDU73NVf/dN4f/D11GhrqNp06YhJCQEWVlZcHNzg66urtzrnTt35imZcseOHUN+fj4OHDiA6OhoLF68GP3794e/vz8+/vhjQa3r/epR6unTp+XmxpVKpfj5559hY2PDQzJFMpmM+/PZs2cxd+5crFixAh4eHhCJRLh06RK++uorrFixgseU1VuxYgW2bt0KoGL9902bNiEyMhInT57EjBkzcPz4cZ4TKvr+++8xZswYAMCJEyeQnp6OP//8E/v27cOCBQvw22+/8Zywat9//z2OHDmCzMxMlJWVyb0mhEmdfv31V+7PGRkZmDdvHiZMmAAPDw8AFd+PvXv3YuXKlXxFfKOnT5/KPX/58iVu3LiBhQsXIjw8nKdUtfDG9bVItUQikcJDTU2N+29TkJiYyL788ksmFouZkZERCw4OZvfu3eM7FmOs6p9v5UNLS4u1b9+enThxgu+YCjp16sTi4+MV2i9cuMA6duzIQyLV6OjosIcPHzLGGJszZw4bO3YsY4yxO3fuMCMjIz6jKaWtrc0tFThp0iQ2ffp0xhhjaWlprGXLljwmU279+vWsRYsW7IsvvmBaWlpsypQprH///kxfX5/Nnz+f73gK+vbty7799luF9oMHDzJPT8/GD1RH58+fZ66urnzHUBkNJquj9PR0hUdaWhr3X6HLzs7GmTNncObMGairq+Ojjz7CH3/8AUdHR6xbt47veJDJZJDJZLC2tsY///zDPZfJZCgtLUVKSgoGDRrEd0wFDx48qHJlHH19fWRkZDR+IBW1aNEC+fn5ACpWpuvfvz8AQCwW499//+UzmlKmpqa4e/cupFIpTp06xWUuLi6Guro6z+mqtmXLFmzfvh2bNm2ClpYW5syZg7i4OAQFBaGgoIDveAouX74Md3d3hXZ3d3f8/vvvPCSqG2NjY6SkpPAdQ3V8/6ZAGl9ZWRn7/vvv2cCBA5mmpiZzc3NjW7duZYWFhVyfQ4cOMQMDAx5T/k9ZWRnz8vJiKSkpfEdRWa9evVjfvn3Z48ePubbs7GzWv39/1rt3bx6TVW/UqFHM1dWV+fv7M4lEwvLy8hhjjP3444+sU6dOPKer2uLFi5m+vj7r2LEjs7KyYiUlJYwxxnbt2sW6d+/Oc7qq6ejosIyMDMYYY8bGxiwpKYkxxti9e/eYoaEhn9Gq1L59exYSEqLQHhISwtq3b89DItXcvHlT7pGUlMT++9//Mk9PT9ajRw++46mMrlHXg/3792Pbtm1IT0/H5cuXYW1tjcjISNja2ipdW5tP5ubmkMlkGDlyJH7//Xd07dpVoY+Pj0+Dr9utKk1NTdy5c0flgS1CsGvXLgwbNgzW1tawsrICAGRmZqJ9+/aIiYnhN1w1Nm/ejK+++gpZWVk4duwYN8o+ISEBI0eO5Dld1cLCwuDk5ISsrCwMHz6cW3RBXV0d8+bN4zld1czMzJCfnw9ra2tYW1vjypUr6NKlC9LT0+UGIArFunXr8Omnn+L06dPo3r07AODKlSt48OABjh07xnM65bp27aowqBMAunfvjt27d/OUqubo9qw62rp1KxYtWoTg4GCEh4fjzp07sLOzQ3R0NPbu3Ss3IEMo9u3bB19fX4jFYr6jqGzmzJnQ1NTEqlWr+I6iMplMhrNnz+LPP/8EYwyOjo7o379/k/qFo6kpKSlpEt/rgIAAWFpaYvHixdi2bRtCQkLQs2dPXL9+HcOGDcOuXbv4jqjgr7/+wtatW5GcnMx9n6dOnQpLS0u+oyn18OFDuedqamowNjZuEt+RV1GhriNHR0esWLECQ4cORcuWLXHz5k3Y2dnhzp078PLyQl5eHt8R5ZSXl0MsFiMpKQlOTk58x1FZYGAg9u3bB3t7e7i7uyuMro+IiOApmaKm+jOuFB8fj6ioKKSlpeHo0aNo06YN9u/fD1tbW7z//vt8x1MglUqxYsUKbNu2DX///Tfu3bsHOzs7LFy4EDY2NvD39+c7ooLKcRYaGhUnNY8cOYKLFy/C3t4eU6dOhZaWFs8J/+fly5fw9vZGVFQU2rdvz3ectxINJquj9PR0uLi4KLRra2vjxYsXPCSqnoaGBqytrZvM/YOV7ty5A1dXV+jp6eHevXu4ceMG90hKSuI7npym+jMGKm7d8/HxgY6ODhITE1FaWgqg4t57od5WFh4ejujoaHz99ddyBc7Z2Rk7d+7kMZlyampqXJEGAF9fX2zYsAFBQUGCKtJA07z09Krz589j8ODBsLe3R7t27TBkyBDEx8fzHatm+Ls83jw4ODiwmJgYxhhjLVq0YA8ePGCMVdx+IdTh/7t372YDBgxg+fn5fEdptprqz7hr165s7969jDH57/ONGzeYqakpn9GUeuedd9jZs2cZY/KZk5OTBTMg8nW2trZswoQJ3MC3Sv/88w+ztbXlKZVyISEhbO7cuXzHqLH9+/czDQ0N5uvry9avX88iIyOZr68v09TUZAcPHuQ7nspoMFkdzZ49G1988QVKSkrAGMPvv/+OQ4cOYeXKlYL9bX7Dhg1ITU2FhYUFrK2tFU4jC2Gyher89ddfEIlEgp5Nran+jFNSUqqcVlFPTw/Pnj1r/EAqePToEezt7RXaZTIZXr58yUOiN8vIyICGhgZ69eqFH3/8Eebm5gAqTuO/fl1VCMrKyrBz507ExcUJ/tLTq8LDw/H1119jxowZXNv06dMRERGBZcuWYdSoUTymUx0V6jry8/NDeXk55syZg+LiYowaNQpt2rTB+vXrMWLECL7jVen1qS6bAplMhuXLl2Pt2rV4/vw5AKBly5aYOXMmFixYADU1YV3FaYo/Y6DijoDU1FSF2d4uXrwIOzs7fkK9QadOnRAfH68wvenRo0ervCwlBCKRCKdOncKsWbPg7u6OmJgYvPvuu3zHUqry0hMA3Lt3T+41IZ8ST0tLw+DBgxXahwwZgvnz5/OQqJb4PqRvTv755x/2999/8x2jWZo3bx4zNjZmW7Zs4e6H3Lx5MzM2NhbkTE5N1erVq5mjoyO7cuUKa9myJYuPj2cHDhxgxsbGbOPGjXzHq9JPP/3E9PX12apVq5hEImHffPMNCwgIYFpaWuzMmTN8x6uSSCTi/q2YN28e09HRYfv372c5OTlNZkbDpuCdd95h27ZtU2jftm0bs7e35yFR7VChrqPi4mL24sUL7nlGRgZbt24dO336NI+p3uzp06dsx44dbN68edx11ISEBPbXX3/xnKxq5ubm7Mcff1Roj4mJYRYWFjwkar7mz5/PdHR0uKlaxWIx++qrr/iOVa1Tp06x3r17M11dXaajo8N69uwp6P8H1dTU5H6p379/PxOLxczPz48KdT3asmUL09LSYlOnTmX79u1j+/fvZ1OmTGHa2tpVFnChotuz6sjb2xvDhg3D1KlT8ezZM3To0AFaWlrIy8tDREQEPv/8c74jKrh16xb69+/PTWeZkpLC3c7y8OFD7Nu3j++ICsRiMW7duqVwe0hKSgq6du0quOktpVIp1q1bp3TRhSdPnvCUTDXFxcW4e/cuZDIZHB0d0aJFC74jNStqamrIycmBiYkJ13b58mV88skn+OeffwR5x8C1a9dw9OjRKr/PQlyspdIPP/yAtWvXIjk5GQDg4OCA2bNnC3IyKqX4/k2hqWvdujW7c+cOY4yxHTt2sM6dOzOpVMqOHDki2MUX+vXrx2bPns0Ykx8l+9tvvzFra2sekyn33nvvscDAQIX2L7/8knXr1o2HRNVbuHAhMzc3Z9988w0Ti8Vs2bJlzN/fn7Vu3ZqtX7+e73jNyoQJE9jZs2eZTCbjO0qd5eTksHPnzvEdQ8GhQ4eYpqYmGzhwINPS0mKDBg1iHTp0YPr6+mzChAl8x1Nq/Pjx7Pz583zHqDMq1HX06mpDw4cPZ2FhYYwxxjIzM5mOjg6f0ZTS09NjqampjDH5Qp2RkcG0tbX5jKbUuXPnmK6uLnNwcGATJ05k/v7+zMHBgbVo0YJduHCB73gK7Ozs2MmTJxljFT/jyp/3+vXr2ciRI/mMVq3nz5+zr776inl4eLB33nmH2drayj2EaPDgwUxbW5tZWFiwkJAQlpiYyHekN1qyZAn7+eefFdqfP3/OlixZwkOi6jk7O7NNmzYxxv73b4ZMJmOTJk1iixYt4jmdcsOGDWPa2trM3t6ehYeHs0ePHvEdqVaoUNeRs7MzW79+PcvMzGR6enrs0qVLjDHGrl+/Ltj7Tk1MTLh/zF4t1KdPn2Zt27blM1q1Hj16xObPn8+GDRvGPvnkE7ZgwQLB/o8nkUi4X+DMzMxYQkICY4yxBw8eMD09PT6jVWvEiBHM3NyczZkzh61bt45FRkbKPYTq6dOnLCoqinl6ejI1NTXm4ODAwsPDWXp6Ot/RqlS5TOvatWvl2oU6mEwikXA/y9atW7Nbt24xxhi7e/cuMzMz4zHZm+Xl5bHIyEjWtWtXpqGhwT788EN25MgRVlZWxnc0lVGhrqOjR48yTU1Npqamxvr378+1r1ixgn344Yc8JlNu0qRJbOjQoaysrIy1aNGCpaWlsYcPHzIXFxduLV8h+OSTT1hBQQFjjLG9e/cqTA4hZO3bt2dXrlxhjDH2/vvvs5UrVzLGGPvuu++YsbExn9Gqpa+vzy5evMh3jDrJyspiX3/9NevYsSNTV1fnO06VRCIR++6775iRkREbP348Ky0tZYwJt1C3bduWK86dO3fm1qa+dOmSoH/xfF1iYiL78ssvmVgsZkZGRiw4OJjdu3eP71hvRIW6HmRnZ7PExEQmlUq5tqtXr7Lk5GQeUylXUFDAevbsyQwMDJi6ujqztLRkmpqarHfv3uz58+d8x+Noampyy0S+PkpW6ObOncvCw8MZYxW/zGloaDB7e3umpaUl6BmebGxs2N27d/mOUWtlZWXshx9+YJ9++ikTi8WCvSOg8vas1NRU5uDgwDw8PFhOTo5gC/XIkSO5o//ly5czY2NjFhAQwKytrdknn3zCczrVPH78mK1atYq1b9+e6erqsnHjxrEPPviAaWhosIiICL7jVYtGfdejpjBj1qt++eUXJCYmQiaTwdXVFf379+c7kpzOnTvD1dUVffr0gZ+fHzZs2AA9Pb0q+44bN66R09XM1atX8dtvv8He3h5DhgzhO45SBw4cwI8//oi9e/dCIpHwHUdlv/76K7799lscO3YMUqkUw4YNw+jRo9G3b1/BTYYDVCzBmZ2dDRMTExQWFsLX1xd//PEHtm3bhiFDhghu1PeTJ09QUlICCwsLyGQyrFmzhltEZOHChWjVqhXfEav08uVL/PTTT9izZw/OnDmDzp07IyAgAKNHj0bLli0BAN999x0+//xzPH36lOe0ylGhrqOmNmMWUDF94eszTwnRb7/9hpkzZ+LBgwd48uQJWrZsWeUsSCKRSPC3OwmZi4uL3M81NTUVjDHY2NhAU1NTrq8Qpz5t27Yt8vPz4ePjg9GjR2Pw4MGCX8bw9duzZDIZgoODsXXrVshkMsEV6qbKyMgIMpkMI0eOxKRJk9C1a1eFPk+fPoWrqyvS09MbP6CKaArROlqwYAF27dqFVatWoWfPnmCM4bfffkNYWBhKSkoQHh7Od0QFdnZ26NGjB8aOHYvhw4fD0NCQ70hV6tmzJ65cuQKg4h+2e/fuyd13KmQWFhbw8vKCl5cXPD090aFDB74jKdVUpzuttGjRIgwfPlywR3VV2bNnD/T19bnnampq2LBhA1xcXHDhwgUek1Vt9OjR3He5KS11uW7dOgwfPrzaX9xatWol6CIN0BF1nVlYWHCnq171448/Ytq0aXj06BFPyZRLTEzEoUOH8N133+Gff/6Bj48PxowZgyFDhkBbW5vveJxhw4YhOjoaenp62Lt3L3x9faGjo8N3LJUcOnQI58+fx7lz53Dv3j2YmprC09OT+8fOwcGB74jNUlO7/NRUTJkyBefPn8e9e/dgZmYGT09P7vvcsWNHvuM1e1So66ipzZj1KsYYzp07J3dt79NPP8Xu3bv5jgYA0NLSwsOHD2Fubi53Ta+p+fvvv/Hrr7/i5MmTOHz4sKBPbV67dg0ymQzdunWTa7969SrU1dXh7u7OUzLlmsrlpw0bNmDy5MkQi8XYsGGD0n4ikQiBgYGNmEx1OTk5OHfuHM6dO8cVbhMTE2RnZ/MdrVmjQl1H3bp1Q7du3RT+xwsMDMS1a9e4U7dCl5iYCH9/f9y6dUswRaSpDyZ7/vw5Ll68yB1Z37hxA46OjvD09MS6dev4jlel9957D3PmzMH//d//ybUfP34cq1evxtWrV3lKplxoaCh27dqFJUuWKFx+mjRpkmAuP9na2uL69eto3bo1bG1tlfYTiURIS0trxGSqe/HiBS5evMgV68TERDg6OuLGjRt8R2vWqFDX0fnz5zFw4EBYWVnBw8MDIpEIly5dQlZWFmJjY9GrVy++IyqVlZWFQ4cO4dtvv8Xt27fh4eGB0aNHC2Z+8kuXLiEkJKRJDibr1q0bbt26BScnJ3h5eaF3797o1asXDAwM+I5WrRYtWuDWrVsKS1qmp6ejc+fOKCoq4imZck3x8tOrKv8JFvJykXPnzsX58+dx8+ZNODk5oXfv3vD09ETv3r0F/51uDmgwWR15enri3r172Lx5M/78808wxjBs2DBMmzYNFhYWfMer0vbt23Hw4EFcvHgRHTt2xOjRoxETEyO4keA9evRosoPJ7t+/D4lEAjs7O9jZ2cHe3r5J/IOmra2Nv//+W6FQZ2dnQ0NDmP9cPHnypMrrpB07dhTcL3Cv2rVrF9atW4f79+8DANq1a4fg4GAEBATwnEzRN998A2NjYyxevBgff/wxjbFoZHRE/RaytLTEiBEjMHr06CpvVxCihw8fIjMzE1FRUUhLS8PRo0fRpk0b7N+/H7a2tnj//ff5jqjg1q1b3LW8+Ph4qKmpwdPTE3369MHUqVP5jlelESNGICcnBz/++CM3KvnZs2cYOnQoTExMcOTIEZ4TKmqKl58WLlyIdevWITAwEB4eHgAqVs/atGkTpk+fjuXLl/OcUN7Nmze5Szjx8fFQV1fnBpN5eXlR4W5gVKhr4datWyr37dy5cwMmqR3GGC5evNikit6xY8cwduxYjB49Gvv378fdu3dhZ2eHLVu24OTJk4iNjeU7YrUSEhKwadMmHDhwQNCDyR49eoTevXsjPz8fLi4uAICkpCSYmpoiLi4OlpaWPCdUpOzyU2ZmJv773/8K8vKTkZERNm7ciJEjR8q1Hzp0CIGBgcjLy+MpmWpu3ryJyMhIwX+fmwthnssSuK5du0IkEuFNv+OIRCJBfoGPHz/OFb3ExESUlpYCAIqKirBixQpBFr3ly5dj27ZtGDduHL777juuvUePHli6dCmPyap248YNbsBNfHw8ioqK0KVLF0yfPh19+vThO55Sbdq0wa1bt3Dw4EHcvHkTOjo68PPzw8iRIxUmPxEKT09PpKSkYOvWrUhOTm4Sl5+kUmmVI+jd3NxQXl7OQ6I3e/07XVhYiK5duwr6+9xc0BF1LTx8+FDlvtbW1g2YpHZcXFwwY8YMjBs3Di1btsTNmzdhZ2eHpKQkfPjhh8jJyeE7ogKJRIK7d+/CxsZGLnNaWhocHR1RUlLCd0Q5GhoacHFx4U4P9u7dW+mIdVJ3JSUluHXrFnJzcyGTyeReE+KUrYGBgdDU1ERERIRc+6xZs/Dvv/9i8+bNPCWrWqtWrfD8+XN06dKFO91N3+nGQ0fUtfBq8V25ciVMTU0xceJEuT67d+/GP//8g7lz5zZ2vDdKSUlB7969Fdr19PTw7Nmzxg+kAnNzc6SmpioMeLt48aLCwCe+SaVSHD9+HO+//75gZ32rzr1793Du3Lkqi96iRYt4SqXcqVOnMG7cOOTn5yuc5RLqWS2gYjDZmTNn0L17dwDAlStXkJWVhXHjxiEkJITr93ox58P+/fupMPOICnUdRUVF4dtvv1Vo79SpE0aMGCHIQt2Uil6lKVOmYPr06di9ezdEIhEeP36My5cvY9asWYIrHurq6vD19UVycnKTK9Q7duzA559/DiMjI5iZmcndMiQSiQT3swaAL7/8EsOHD8eiRYtgamrKdxyV3LlzB66urgCABw8eAACMjY1hbGyMO3fucP2EcsvWoEGDuD/T7G88aJxFupovbW1tlpaWptD+4MEDpq2tzUOiN1u9ejVzdHRkV65cYS1btmTx8fHswIEDzNjYmG3cuJHveErNnz+f6ejoMJFIxEQiEROLxeyrr77iO1aV3N3d2dmzZ/mOUWNWVlZs1apVfMeokZYtW7LU1FS+YzRrUqmULVmyhOnp6TE1NTWmpqbG9PX12dKlS+WW9yUNgwp1Hdnb27P9+/crtO/bt4/Z2trykEg1TanoverFixfs2rVr7OrVq6yoqIjvOEqdPn2ade3alZ04cYI9fvyYFRQUyD2EqmXLluzBgwd8x6gRPz8/tnPnTr5jNGvz5s1jxsbGbMuWLezmzZssKSmJbd68mRkbG7P58+fzHa/Zo8FkdbR69Wp88803+Oabb9C3b18AwM8//4w5c+Zg5syZCA0N5TmhcsXFxbh79y5kMhkcHR3RokULviM1G6/OL/3q6UvGmKCvm/r7++Pdd98V7H3eVSkuLsbw4cNhbGwMZ2dnhdHpQUFBPCVrPpr67G9NHV2jrqM5c+bgyZMnmDZtGsrKygBULNQxd+5cQRdpoGIktRAXWWgOfv31V74j1Iq9vT0WLlyIK1euNJmi9+233+L06dPQ0dHBuXPnFK6rCzFzU9NUZ39rLuiIup48f/4cycnJ0NHRQbt27QS1XCQhqmqKi0WYmZkhKCgI8+bNE8xKWc1NU5z9rTmhQk1IA3n27Bl27dqF5ORkiEQiODo6YuLEidzUnKR+GBoa4tq1a3jnnXf4jtJsNeXFh5oDKtSENIDr16/Dx8cHOjo6eO+998AYw/Xr1/Hvv//izJkz3K05QhASEoJly5ZBV1dX7v7d14lEIqxdu7YRk6lmxowZMDY2xvz58/mO0mxlZmZCQ0NDbvEhR0dHTJs2DeXl5bCysuI7YrNGhZqQBtCrVy/Y29tjx44d3KpT5eXlCAgIQFpaGi5cuMBzwv/p06cPfvjhBxgYGFQ7HaRIJMIvv/zSiMlUExQUhH379qFLly7o3LmzwnV1IUwY0tSpq6sjOztbYfW6/Px8mJiYCHZwZHNBhZqQBqCjo4MbN24oDMC5e/cu3N3dUVxczFOy5qcp/nLR1KipqSEnJ0ehUD98+BCOjo548eIFT8neDjTqm5AGoKenh8zMTIVCnZWVhZYtW/KUqnlqqiPsm4LKSyGVs9JJJBLuNalUiqtXrzaZpXKbMirUhDSAzz77DP7+/lizZg169OgBkUiEixcvYvbs2QpLGxIiVDdu3ABQcf//7du3oaWlxb2mpaWFLl26YNasWXzFe2vQqW9C6smtW7fg5OQENTU1lJWVYfbs2di2bRu3bKGmpiY+//xzrFq1im7fI02Kn58f1q9fT4ty8IQKNSH15NUBN3Z2drh27Rp0dHSQmpoKoGIykVdPHRJCiCro1Dch9cTAwADp6ekwMTFBRkYGZDIZJBIJOnfuzHc0QkgTRoWakHry6aefwtPTE+bm5hCJRHB3d4e6unqVfYU4wxchRJioUBNST7Zv345hw4YhNTUVQUFBmDRpEo3wJoTUGV2jJqQB+Pn5YcOGDVSoCSF1RoWaEEIIETBaaoYQQggRMCrUhBBCiIBRoSaEEEIEjAo1IYQQImBUqAkhhBABo0JNCCGECBgVakIIIUTAqFATQgghAvb/AICpFbMjZVPRAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可以通过一种称为temperature scaling的方法进一步控制分布和选择过程，所谓temperature scaling，其实就是将 logits 除以一个大于 0 的数\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "#Temperatures greater than 1 result in more uniformly distributed token probabilities, and Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions. Let's illustrate this by plotting the original probabilities alongside probabilities scaled with different temperature values:\n",
    "temperatures = [1, 0.1, 5]             #A\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#A 原始、较低和较高置信度"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:47.896691700Z",
     "start_time": "2025-04-08T12:18:47.735905800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n",
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3.2：Top-k 采样\n",
    "\n",
    "temperature scaling 有时会导致生成语法不正确或完全不合逻辑的内容\n",
    "'''\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)\n",
    "\n",
    "# 应用 PyTorch 的 where 函数，将非 top-3 的 token 的 logit 值设为负无穷大（-inf）\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],   #A\n",
    "    input=torch.tensor(float('-inf')),              #B\n",
    "    other=next_token_logits                         #C\n",
    ")\n",
    "print(new_logits)\n",
    "\n",
    "#A 识别出小于 top 3 最小值的 logits\n",
    "#B 将这些较小的 logits 赋值为负无穷大\n",
    "#C 保留所有其他 token 的原始 logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:49.134110600Z",
     "start_time": "2025-04-08T12:18:49.123979600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n",
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "# 应用 softmax 函数将其转化为下一词的概率分布\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)\n",
    "\n",
    "'''\n",
    "3.3：对文本生成函数进行调整\n",
    "'''\n",
    "# A modified text generation function with more diversity\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):                             #A\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:                                   #B\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:                                       #C\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:                                                       #D\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:                                      #E\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "#A For循环与之前相同：获取logits，仅关注最后的时间步\n",
    "#B 在新步骤中，通过top-k采样过滤logits\n",
    "#C 在新步骤中应用temperature scaling\n",
    "#D 在未使用temperature scaling时，执行贪婪的下一个token选择\n",
    "#E 如果遇到序列结束token且指定了eos_id，则提前停止生成\n",
    "\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:18:51.600168200Z",
     "start_time": "2025-04-08T12:18:50.513819700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(256, 768)\n  (drop_emb): Dropout(p=0.1, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4: 在 PyTorch 中加载和保存模型权重\n",
    "'''\n",
    "# 推荐的做法是保存模型的 state_dict（状态字典），这是一个字典，用于将模型的每一层映射到其对应的参数上，可以通过 torch.save 函数来实现\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# 使用 state_dict 保存模型权重后，可以将权重加载到新的 GPTModel 模型实例中\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T10:26:36.189076500Z",
     "start_time": "2025-04-09T10:26:34.005079700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(256, 768)\n  (drop_emb): Dropout(p=0.1, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=False)\n        (W_key): Linear(in_features=768, out_features=768, bias=False)\n        (W_value): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdamW 等自适应优化器会为每个模型参数存储额外信息。AdamW 使用历史数据动态调整每个模型参数的学习率。\n",
    "# 没有这些信息时，优化器会重置，模型可能无法有效学习，甚至无法正确收敛，进而失去生成连贯文本的能力。可以使用 torch.save 保存模型和优化器的状态\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T10:26:08.458845800Z",
     "start_time": "2025-04-09T10:26:03.158343Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "('gpt_download.py', <http.client.HTTPMessage at 0x14d15ec4d90>)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "5: 从 OpenAI 加载预训练权重\n",
    "'''\n",
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:19:04.368285100Z",
     "start_time": "2025-04-08T12:19:03.495390900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l00841179\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T11:31:11.117841500Z",
     "start_time": "2025-04-08T11:31:04.491494800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 79.1kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 7.56MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 92.3kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [17:04<00:00, 486kiB/s]    \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 5.21MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 19.5MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 6.25MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T11:49:14.527404100Z",
     "start_time": "2025-04-08T11:31:23.716049100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n",
    "\n",
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T11:51:11.781733Z",
     "start_time": "2025-04-08T11:51:11.772373900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "# 在将 GPT-2 模型的权重加载到 Python 后，我们还需要将这些权重从 settings 和 params 字典转移到 GPTModel 实例中\n",
    "#  create a dictionary that lists the differences between the different GPT model sizes, as explained in Figure 5.17:\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "# Suppose we are interested in loading the smallest model, \"gpt2-small (124M)\". We can use the corresponding settings from the model_configs table able to update our full-length GPT_CONFIG_124M we defined and used earlier throughout the chapter as follows:\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "\n",
    "# 之前设置的 token 长度是 256，但 OpenAI 的原始 GPT-2 模型使用的是 1,024 的 token 长度\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "# We can now use the updated NEW_CONFIG dictionary to initialize a new GPTModel instance:\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "\n",
    "\n",
    "# 定义一个简单的assign工具函数，用于检查两个张量或数组（左侧和右侧）的维度或形状是否一致，并将右侧张量作为可训练的 PyTorch 参数返回\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "# Loading OpenAI weights into our GPT model code\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])               #A\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):                                       #B\n",
    "        q_w, k_w, v_w = np.split(                                                #C\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])                   #D\n",
    "\n",
    "\n",
    "#A 将模型的位置嵌入和token 嵌入的权重设置为 params 中指定的值\n",
    "#B 遍历模型中的每个 Transformer 模块\n",
    "#C 使用 np.split 函数将注意力和偏置权重分为三等份，分别用于查询、键和值组件\n",
    "#D OpenAI 的原始 GPT-2 模型在输出层中复用了 token 嵌入的权重，以减少参数总量，这一概念称为权重共享\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T03:15:25.562375400Z",
     "start_time": "2025-04-09T03:15:22.824782200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
