{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T03:44:10.504686700Z",
     "start_time": "2025-04-11T03:44:04.528398200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n",
      "[50256]\n",
      "120\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n",
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "LoRA，即低秩适应，是一种仅调整模型权重参数的一小部分，就可以让预训练模型更好地适应特定（通常较小）数据集的技术。\n",
    "“低秩”指的是将模型调整限制在总权重参数空间的一个较小维度子空间的数学概念，这有效地捕获了训练期间权重参数变化的最具影响力的方向。\n",
    "LoRA 的好处就是，它能让预训练模型快速适应新的任务，而且只需要学习和调整很少的“小工具”，这样就更高效、更省资源。\n",
    "\n",
    "LoRA 的权重是独立于原始模型权重的：\n",
    "1. 原始的“超级大脑”保持不变\n",
    "2. “插件”很小，训练起来更快更省资源\n",
    "3. 可以灵活地切换任务\n",
    "4. 部署和存储更方便\n",
    "'''\n",
    "\n",
    "'''\n",
    "如何将文本消息分类为垃圾短信或正常短信\n",
    "\n",
    "微调语言模型最常见的方法是指令微调和分类微调\n",
    "指令微调：通过在一组任务上使用特定指令训练模型，用以提升模型对自然语言提示中任务描述的理解和执行能力\n",
    "分类微调：模型被训练用来识别特定的一组类别标签\n",
    "'''\n",
    "\n",
    "'''\n",
    "1： 准备数据集\n",
    "'''\n",
    "from pathlib import Path\n",
    "\n",
    "data_file_path = \"D:\\codes\\llm-evaluation\\ch_6\\sms_spam_collection\\SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "#A 下载数据集\n",
    "#B 解压数据集\n",
    "#C 为解压的数据集文件设置.tsv文件扩展名\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df  #A\n",
    "\n",
    "#A 在 Jupyter Notebook 中可以直接渲染数据，或者用 print(df) 命令显示数据内容\n",
    "# 统计分类情况\n",
    "print(df[\"Label\"].value_counts())\n",
    "'''\n",
    "我们选择对数据集进行下采样，每个类别保留 747 个样本，为了更快的进行微调\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Creating a balanced dataset\n",
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]  #A\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)  #B\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])  #C\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())\n",
    "\n",
    "#A 统计垃圾短信的实例数量\n",
    "#B 随机抽取正常邮件实例，使其数量与垃圾短信实例相同。\n",
    "#C 将正常短信子集与垃圾短信合并\n",
    "\n",
    "# 将字符串类别标签 \"ham\" 和 \"spam\" 分别转换为整数类别标签 0 和 1\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "'''\n",
    "创建一个random_split函数，将数据集划分为三部分：70%用于训练，10%用于验证，20%用于测试\n",
    "'''\n",
    "\n",
    "\n",
    "# Splitting the dataset\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)  #A\n",
    "\n",
    "    train_end = int(len(df) * train_frac)  #B\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]  #C\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)  #D\n",
    "\n",
    "#A 将整个 DataFrame 随机打乱\n",
    "#B 计算数据分割的索引\n",
    "#C 分割 DataFrame\n",
    "#D 测试集默认大小为 0.2（即剩余部分）\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)\n",
    "'''\n",
    "2： 创建数据加载器\n",
    "\n",
    "为了像第 2 章中的文本块那样对这些消息进行批处理，我们有两种处理方式：\n",
    "\n",
    "将所有消息截断至数据集或批次中最短消息的长度。\n",
    "将所有消息填充到数据集或批次中最长消息的长度。\n",
    "\n",
    "方案一的计算成本较低，但如果较短的消息远小于平均长度或最长消息长度，可能会导致显著的信息损失，从而降低模型的性能。因此，我们选择方案二，以完整保留所有消息的内容。\n",
    "'''\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n",
    "\n",
    "# 定义SpamDataset类：识别训练数据集中最长的序列，对文本消息进行编码，并确保通过填充 token 将其他序列补齐到与最长序列相同的长度\n",
    "# Setting up a Pytorch Dataset class\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [  #A\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [  #B\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        self.encoded_texts = [  #C\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "\n",
    "\n",
    "#A 对文本进行预分词\n",
    "#B 若序列超过最大长度则进行截断\n",
    "#C 将序列填充至最长序列长度\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "# Creating PyTorch data loaders\n",
    "# 创建训练集、验证集和测试集的数据加载器，以批量大小为 8 加载文本消息及其标签\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0  #A\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "#A 此设置可确保与大多数计算机兼容\n",
    "\n",
    "# 为了确保数据加载器正常工作并确实返回了预期大小的批次数据，可以遍历训练集数据加载器，并打印最后一个批次的张量维度\n",
    "\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)\n",
    "\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")\n",
    "'''\n",
    "3: 使用预训练权重初始化模型\n",
    "'''\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,  # Dropout rate\n",
    "    \"qkv_bias\": True  # Query-key-value bias\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l00841179\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n",
      "torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n",
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([3.9108e-05, 5.6776e-05, 4.7559e-06])\n",
      "tensor([ -9.5042, -10.3796, -11.3677, -10.1492,  -9.7764, -12.2561])\n",
      "tensor(-10.5722)\n",
      "tensor(10.5722)\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "tensor(10.5722)\n",
      "Characters: 20479\n",
      "Tokens: 5145\n",
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.981106758117676\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren Mortgage TT remember gard ACTIONSussedOND Land Engeleddedemate breaths proxies GalaxyForm\n",
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": "GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.0, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a pretrained GPT model\n",
    "from ch_5.gpt_download import download_and_load_gpt2\n",
    "from ch_4.build_gpt import GPTModel, generate_text_simple\n",
    "from ch_5.ch5 import load_weights_into_gpt, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T03:46:01.969413400Z",
     "start_time": "2025-04-11T03:44:53.287684900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n",
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    },
    {
     "data": {
      "text/plain": "GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.0, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 将模型权重加载到GPTModel后，我们使用前面章节的文本生成工具函数，确保模型能够生成连贯的文本\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n",
    "# 看看这个模型是否能通过给它提供指令来对垃圾短信进行分类\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n",
    "'''\n",
    "4： 添加分类头\n",
    "\n",
    "为分类任务的微调做准备：\n",
    "输出层将隐层表示映射到50,257个词汇的词汇表，而我们用一个较小的输出层将其映射到两个类别：0（‘非垃圾短信’）和1（‘垃圾短信’）\n",
    "'''\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T03:46:47.677528900Z",
     "start_time": "2025-04-11T03:46:45.099013700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# 为了计算分类准确率，我们对数据集中的所有样本进行 argmax 预测，并通过定义一个 calc_accuracy_loader 函数来计算预测正确的比例\n",
    "# Calculating the classification accuracy\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]                   #A\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n",
    "\n",
    "#A 最后一个输出 token 的 logits 值\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 可以使用这个函数来估算多个数据集上的分类准确率，为提高效率，这里基于 10 个批次的结果进行估算\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T03:48:55.607775700Z",
     "start_time": "2025-04-11T03:48:33.352375200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n秩 (Rank):\\n\\n决定了 LoRA “小工具” 的大小: 还记得之前我们把 LoRA 比作给预训练模型添加一些专门的“小工具”吗？这里的“秩”就决定了这些“小工具”（更具体地说是矩阵 A 和 B）的内部大小。你可以想象成，秩越大，“小工具”就越复杂，包含的信息就越多。\\n影响额外学习的参数数量: 秩越大，LoRA 引入的需要学习的额外参数就越多。反之，秩越小，需要学习的参数就越少。\\n平衡模型的学习能力和效率:\\n秩高一点: 模型可以学习到更复杂、更细致的针对特定任务的调整，性能可能会更好。但是，需要学习的参数也更多，训练起来可能更慢，更耗费资源。\\n秩低一点: 模型学习的参数更少，训练速度更快，更节省资源。但是，如果秩太低，模型可能没有足够的“能力”来学习到足够好的调整，导致性能不够理想。\\n就像给自行车加辅助轮: 秩就像辅助轮的大小。大的辅助轮（高秩）更容易保持平衡，但可能不够灵活。小的辅助轮（低秩）更灵活，但可能需要更高的骑行技巧。你需要找到一个合适的平衡点。\\nAlpha:\\n\\nLoRA “小工具” 输出的音量调节器: Alpha 可以看作是一个调节 LoRA 带来的改变有多大的“音量旋钮”。它是一个数字，用来乘以 LoRA “小工具” 的输出结果。\\n控制适应层对原始层的影响: Alpha 的大小决定了 LoRA 学习到的调整对原始模型输出的影响程度。\\nAlpha 大一点: LoRA 带来的改变会更明显，模型会更倾向于学习新的任务。\\nAlpha 小一点: LoRA 带来的改变会更微妙，模型更多地还是依赖于它原本学到的知识，只是做一些微小的调整。\\n就像调味品: Alpha 就像你做菜时放的盐。盐放多了（Alpha 大了），菜的味道变化就大；盐放少了（Alpha 小了），菜的味道变化就小。你需要根据你的口味来调整。\\n总结一下：\\n\\n秩 (Rank) 决定了 LoRA 可以学习多少新的信息，以及需要多少额外的参数。\\nAlpha 决定了 LoRA 学习到的信息对最终结果的影响有多大。\\n这两个参数都需要根据具体的任务和模型进行调整，以达到最佳的性能和效率。\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "alpha用作低秩适应输出的缩放因子。它主要决定了来自适应层的输出对原始层输出的影响程度。这可以看作是一种调节低秩适应对层输出影响的方式\n",
    "'''\n",
    "\n",
    "# Implementing a LoRA layer\n",
    "\n",
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))      #A\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x\n",
    "\n",
    "\n",
    "#A 使用与 PyTorch 中线性层相同的初始化方式\n",
    "'''\n",
    "秩 (Rank):\n",
    "\n",
    "决定了 LoRA “小工具” 的大小: 还记得之前我们把 LoRA 比作给预训练模型添加一些专门的“小工具”吗？这里的“秩”就决定了这些“小工具”（更具体地说是矩阵 A 和 B）的内部大小。\n",
    "你可以想象成，秩越大，“小工具”就越复杂，包含的信息就越多。\n",
    "影响额外学习的参数数量: 秩越大，LoRA 引入的需要学习的额外参数就越多。反之，秩越小，需要学习的参数就越少。\n",
    "平衡模型的学习能力和效率:\n",
    "秩高一点: 模型可以学习到更复杂、更细致的针对特定任务的调整，性能可能会更好。但是，需要学习的参数也更多，训练起来可能更慢，更耗费资源。\n",
    "秩低一点: 模型学习的参数更少，训练速度更快，更节省资源。但是，如果秩太低，模型可能没有足够的“能力”来学习到足够好的调整，导致性能不够理想。\n",
    "就像给自行车加辅助轮: 秩就像辅助轮的大小。大的辅助轮（高秩）更容易保持平衡，但可能不够灵活。小的辅助轮（低秩）更灵活，但可能需要更高的骑行技巧。你需要找到一个合适的平衡点。\n",
    "Alpha:\n",
    "\n",
    "LoRA “小工具” 输出的音量调节器: Alpha 可以看作是一个调节 LoRA 带来的改变有多大的“音量旋钮”。它是一个数字，用来乘以 LoRA “小工具” 的输出结果。\n",
    "控制适应层对原始层的影响: Alpha 的大小决定了 LoRA 学习到的调整对原始模型输出的影响程度。\n",
    "Alpha 大一点: LoRA 带来的改变会更明显，模型会更倾向于学习新的任务。\n",
    "Alpha 小一点: LoRA 带来的改变会更微妙，模型更多地还是依赖于它原本学到的知识，只是做一些微小的调整。\n",
    "就像调味品: Alpha 就像你做菜时放的盐。盐放多了（Alpha 大了），菜的味道变化就大；盐放少了（Alpha 小了），菜的味道变化就小。你需要根据你的口味来调整。\n",
    "总结一下：\n",
    "\n",
    "秩 (Rank) 决定了 LoRA 可以学习多少新的信息，以及需要多少额外的参数。\n",
    "Alpha 决定了 LoRA 学习到的信息对最终结果的影响有多大。\n",
    "这两个参数都需要根据具体的任务和模型进行调整，以达到最佳的性能和效率。\n",
    "'''\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T03:52:30.638522700Z",
     "start_time": "2025-04-11T03:52:30.624941500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "'''\n",
    "现在创建一个 LinearWithLoRA 层。该层利用了之前实现的 LoRALayer，旨在替换神经网络中现有的线性层，例如 GPTModel 中的自注意力模块或前馈模块\n",
    "'''\n",
    "# A LinearWithLora layer to replace Linear layers\n",
    "\n",
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "   \t\t return self.linear(x) + self.lora(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T03:52:58.414249500Z",
     "start_time": "2025-04-11T03:52:58.402085100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 引入了一个 replace_linear_with_lora 函数。该函数会将模型中所有现有的线性层替换为新创建的 LinearWithLoRA 层\n",
    "\n",
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):               #A\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:                                                 #B\n",
    "            replace_linear_with_lora(module, rank, alpha)\n",
    "\n",
    "\n",
    "#A 将线性层替换为 LinearWithLoRA\n",
    "#B 将相同的函数递归地应用于子模块"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T03:53:45.793934300Z",
     "start_time": "2025-04-11T03:53:45.780112900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "# 使用上述函数进行层升级前，需要冻结原始模型的参数\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "\tparam.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T06:29:55.255215600Z",
     "start_time": "2025-04-11T06:29:55.250719700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")\n",
    "\n",
    "'''\n",
    "使用 LoRA 后，可训练参数的数量减少了近 50 倍。秩和 alpha 一般都默认设置为 16 ，但通常也会增加秩的大小，这从而增加可训练参数的数量。Alpha 通常选择为秩的一半、两倍或相等\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T06:33:02.870082200Z",
     "start_time": "2025-04-11T06:33:02.834708700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T06:33:42.233710500Z",
     "start_time": "2025-04-11T06:33:42.221004200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "'''\n",
    "与之前的初始值进行比较，我们会发现它们是相同的。这是因为我们将 LoRA 矩阵 B 初始化为零。\n",
    "因此，矩阵 AB 的乘积得到一个零矩阵。这确保了在开始微调之前，该乘法不会改变原始权重，因为加零不会改变它们\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T06:44:52.295843Z",
     "start_time": "2025-04-11T06:44:28.050721800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "'''\n",
    "定义损失函数，以便在训练过程中对其进行优化：最大化模型的垃圾短信分类准确率，因此代码输出应为正确的类别标签：0 表示正常短信，1 表示垃圾短信\n",
    "'''\n",
    "# 与之前的区别是：我们只优化最后一个 token（model(input_batch)[:, -1, :]），而不是整个序列中的所有 token（model(input_batch)）\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :] # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "# Calculating the classification loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:                                      #A\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "'''\n",
    "使用监督数据对模型进行微调\n",
    "'''\n",
    "\n",
    "# 与之前的唯一区别：现在记录的是训练样本数量（examples_seen），而不是 token 数量；并且在每个 epoch 后计算准确率，而不再打印示例文本\n",
    "# Finetuning the model to classify spam\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs, eval_freq, eval_iter, tokenizer):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()                                      #A\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()                          #B\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()                                #C\n",
    "            optimizer.step()                               #D\n",
    "            examples_seen += input_batch.shape[0]          #E\n",
    "            global_step += 1\n",
    "\n",
    "\n",
    "            if global_step % eval_freq == 0:               #F\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(             #G\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "#A 设置模型为训练模式\n",
    "#B 重置上一批次的损失梯度\n",
    "#C 计算损失梯度\n",
    "#D 使用损失梯度更新模型权重\n",
    "#E 更改逻辑：跟踪样本数量而非 token 数量\n",
    "#F 可选评估步骤\n",
    "#G 每个 epoch 后计算准确率\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T06:47:40.902068800Z",
     "start_time": "2025-04-11T06:47:40.889079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.820, Val loss 3.462\n",
      "Ep 1 (Step 000050): Train loss 0.396, Val loss 0.364\n",
      "Ep 1 (Step 000100): Train loss 0.111, Val loss 0.229\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.135, Val loss 0.073\n",
      "Ep 2 (Step 000200): Train loss 0.010, Val loss 0.044\n",
      "Ep 2 (Step 000250): Train loss 0.027, Val loss 0.179\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.224, Val loss 0.050\n",
      "Ep 3 (Step 000350): Train loss 0.045, Val loss 0.081\n",
      "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
      "Ep 4 (Step 000400): Train loss 0.014, Val loss 0.059\n",
      "Ep 4 (Step 000450): Train loss 0.012, Val loss 0.103\n",
      "Ep 4 (Step 000500): Train loss 0.001, Val loss 0.019\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.001, Val loss 0.049\n",
      "Ep 5 (Step 000600): Train loss 0.009, Val loss 0.080\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Training completed in 22.63 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T07:13:02.070691200Z",
     "start_time": "2025-04-11T06:50:24.269964Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x300 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the classification loss\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")    #A\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()                                                 #B\n",
    "    ax2.plot(examples_seen, train_values, alpha=0) # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()                                                #C\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#A 绘制训练轮次与训练和验证损失的变化图\n",
    "#B 创建一个新的 x 轴，用于显示已处理样本数\n",
    "#C 调整布局以留出空间\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T07:13:19.631453100Z",
     "start_time": "2025-04-11T07:13:18.678223900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.62%\n",
      "Validation accuracy: 96.64%\n",
      "Test accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "'''\n",
    "结果表明存在轻微的过拟合，因为与训练集相比，该模型在新数据上的泛化能力稍差。\n",
    "总的来说，考虑到我们只微调了相对较少数量的模型权重（270 万个 LoRA 权重，而不是原来的 1.24 亿个模型权重），结果已经不错了。\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T07:16:11.764208100Z",
     "start_time": "2025-04-11T07:13:32.100441900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
